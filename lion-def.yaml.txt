apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: 2019-04-12T11:35:24Z
  name: lion
  namespace: default
  resourceVersion: "2659"
  selfLink: /api/v1/namespaces/default/pods/lion
  uid: 101f7a83-5d17-11e9-a3f7-0242ac110006
spec:
  containers:
  - args:
    - -cpus
    - "1"
    image: vish/stress
    imagePullPolicy: Always
    name: cpu-stress
    resources:
      limits:
        cpu: "200"
      requests:
        cpu: "100"
    terminationMessagePath: /dev/termination-log
    terminationMessagePolicy: File
    volumeMounts:
    - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      name: default-token-29ntv
      readOnly: true
  dnsPolicy: ClusterFirst
  priority: 0
  restartPolicy: Always
  schedulerName: default-scheduler
  securityContext: {}
  serviceAccount: default
  serviceAccountName: default
  terminationGracePeriodSeconds: 30
  tolerations:
  - effect: NoExecute
    key: node.kubernetes.io/not-ready
    operator: Exists
    tolerationSeconds: 300
  - effect: NoExecute
    key: node.kubernetes.io/unreachable
    operator: Exists
    tolerationSeconds: 300
  volumes:
  - name: default-token-29ntv
    secret:
      defaultMode: 420
      secretName: default-token-29ntv
status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: 2019-04-12T11:35:24Z
    message: '0/2 nodes are available: 2 Insufficient cpu.'
    reason: Unschedulable
    status: "False"
    type: PodScheduled
  phase: Pending
  qosClass: Burstable